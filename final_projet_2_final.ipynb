{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb51b8e-00ab-4d7b-8ef4-c6a29653e8d8",
   "metadata": {},
   "source": [
    "### Projet 2 - Analyse d’un phénomène environnemental inconnu.\n",
    "\n",
    "**À rendre avant le 19.12.2024 minuit.**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Synopsis**\n",
    "\n",
    "Vous travaillez comme data scientist pour une entreprise spécialisée dans la modélisation de systèmes physiques complexes. Une équipe d'experts a collecté des données sur un phénomène environnemental à l’aide d’un réseau de capteurs. Ces données, enregistrées toutes les 15 minutes entre le **1er janvier 2024** et le **29 février 2024**, contiennent des informations provenant de trois capteurs. Malheureusement, un capteur est devenu défectueux à partir du **20 février**, et votre objectif est d’approximer les valeurs manquantes.\n",
    "\n",
    "Le jeu de données non défecteuses sont disponibles dans le fichier _[./projet_2_data.csv](./projet_2_data.csv)_. Les colonnes sont :\n",
    "\n",
    "1. **timestamp** : la date et l'heure de chaque observation (au format datetime).\n",
    "2. **x1** : une première mesure physique observable liée au système.\n",
    "3. **x2** : une seconde mesure physique observable liée au système.\n",
    "4. **y** : la variable cible à reconstituer, représentant un comportement du système physique.\n",
    "\n",
    "Le jeu de données défecteuses sont disponibles dans le fichier _[./projet_2_hold_out.csv](./projet_2_hold_out.csv)_ qui n'inclus pas la variable cible.\n",
    "\n",
    "Les experts soupçonnent que la variable cible **y** dépend de plusieurs facteurs :\n",
    "- L’activité anthropique (jour de semaine ou week-end, heure de la journée, etc) selon un motif cyclique.\n",
    "- Les interactions temporelles des variables **x1** et **x2**, incluant un potentiel **décalage dans le temps (lag)** pouvant aller jusqu’à 30 minutes.\n",
    "\n",
    "Votre mission consiste à découvrir cette relation pour créer un modèle prédictif permettant de reconstituer les valeurs manquantes de **y**. Il vous revient de décider quel type de modèle est le plus adapté pour capturer cette relation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Important**\n",
    "\n",
    "Ce problème est une simulation contenant des variables fictives. Il ne repose pas sur des connaissances physiques réelles. Ne vous appuyez pas sur une expertise métier pour résoudre ce problème : basez vos décisions sur les données et vos analyses, et des informations données ci-dessus.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Objectifs**\n",
    "\n",
    "1. **Analyse exploratoire** :\n",
    "   - Visualiser les variations de **y** en fonction du temps, des variables explicatives, et des caractéristiques temporelles, etc.\n",
    "   - Identifier des motifs cycliques ou des relations structurelles dans les données.\n",
    "\n",
    "2. **Transformation des données** :\n",
    "   - Extraire et créer des nouvelles caractéristiques pertinentes.\n",
    "   - Traiter les valeurs manquantes de manière appropriée.\n",
    "\n",
    "3. **Construction du modèle** :\n",
    "   - Concevez un modèle capable de capturer efficacement les relations entre les variables explicatives et la variable cible.\n",
    "   - Vous pouvez tester plusieurs approches et choisir celle offrant les meilleures performances.\n",
    "\n",
    "4. **Évaluation des performances** :\n",
    "   - Utiliser des métriques adaptées pour mesurer la qualité des prédictions.\n",
    "   - Vous pouvez comparer les performances entre plusieurs modèles ou configurations.\n",
    "\n",
    "5. **Présentation des résultats** :\n",
    "   - Fournir un rapport clair et structuré expliquant vos choix méthodologiques, vos résultats, et vos conclusions.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Livrables**\n",
    "\n",
    "1. **Modèle prédictif** :\n",
    "   - Un modèle entraîné sur les données avant le 20 février.\n",
    "\n",
    "2. **Fonction de transformation** :\n",
    "   - Une fonction python permettant de préparer des données brutes à partir d'un fichier similaire à _[projet_2_hold_out.csv](./projet_2_hold_out.csv)_, qui peuvent être utilisées avec votre modèle prédictif. Cette fonction doit retourner une DataFrame pandas ou un array numpy utilisable par votre modèle (voir exemple _inputTransform_).\n",
    "\n",
    "3. **Rapport** :\n",
    "   - Fournissez un _[rapport](./rapport.ipynb)_ bref et clair expliquant vos choix, vos résultats et les performances des modèles.\n",
    "   - Explication des étapes d’analyse exploratoire et de création des caractéristiques, avec une description claire des caractéristiques sélectionnées et de la méthodologie.\n",
    "   - Méthode de création du modèle, régularisations etc, avec justification de vos choix.\n",
    "   - Performance du modèle, et interpretation.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Astuces**\n",
    "\n",
    "1. **Séries temporelles** :\n",
    "   - Assurez-vous de respecter l’ordre chronologique lors de la division des données en ensembles d’entraînement et de validation.\n",
    "\n",
    "3. **Caractéristiques temporelles** :\n",
    "   - Transformez les informations temporelles en variables utiles (par exemple, type de jour, heure, etc.).\n",
    "   - Explorez l’influence des décalages temporels. Par exemple, la valeur de **x1** à un instant donné pourrait influencer **y** avec un retard de 15 ou 30 minutes.\n",
    "\n",
    "4. **Nettoyage avant soumission** :\n",
    "   - Vérifiez que votre notebook s'exécute correctement de bout en bout en utilisant l’option _Restart Kernel and Run All Cells…_. Ensuite, nettoyez les sorties avec _Restart Kernel and Clear All Outputs…_.\n",
    "  \n",
    "5. **Fonctions utiles** :\n",
    "   - _pandas.DataFrame.shift_ : pour créer des décalages temporels sur vos colonnes.\n",
    "   - _pandas.concat_ : pour combiner plusieurs DataFrames ou colonnes.\n",
    "   - _pandas.get_dummies_ : pour créer des variables indicatrices (dummy variables) à partir de colonnes catégoriques.\n",
    "   - _pandas.read_csv_ : pour lire les données et traiter les timestamps correctement.\n",
    "   - _pandas.dropna_ : pour gérer les valeurs manquantes dans vos données.\n",
    "   - Fonctions de conversion des colonnes datetime : par exemple, _df.timestamp.dt.hour_, _df.timestamp.dt.minute_, et autres méthodes de l’objet pandas datetime pour extraire des informations temporelles pertinentes.\n",
    "   - _sklearn.model_selection.TimeSeriesSplit_ : pour diviser vos données temporelles en ensembles d'entraînement et de test tout en respectant l'ordre chronologique (sinon KFold, etc. changent l'ordre de manière aléatoire).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **Évaluation**\n",
    "\n",
    "Cette question admet plusieurs solutions possibles. Une partie de la note sera attribuée en fonction de la cohérence et de la justification de vos choix. Votre rapport devra inclure une discussion expliquant la méthode utilisée, ainsi que l'interpretation des résultats obtenus.\n",
    "\n",
    "---\n",
    "\n",
    "#### Barème - sur 6 points\n",
    "\n",
    "1. **Qualité de la méthode et du code** :\n",
    "    - Noté sur 3 points, en tenant compte de la clarté, de l'organisation et de l'efficacité de l'approches utilisée.\n",
    "\n",
    "2. **Vérification et analyse des résultats** :\n",
    "    - Noté sur 3 points, en fonction de la rigueur dans l'évaluation du modèle et de la pertinence des conclusions.\n",
    "\n",
    "3. **Fonctionnalité** :\n",
    "    - Des points seront déduits si le notebook n'est pas fonctionnel, en fonction de la gravité des problèmes rencontrés et du nombre de corrections nécessaires pour le rendre opérationnel.\n",
    "\n",
    "Les notes incluent une évaluation des réponses fournies dans le rapport, en particulier la justification des choix effectués et l'interprétation des résultats et performances du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25fa00e",
   "metadata": {},
   "source": [
    "# Projet 2 - Analyse d’un phénomène environnemental inconnu\n",
    "\n",
    "Dans cette version, nous incluons une étape de séparation des données en ensembles d'entraînement et de test en respectant l'ordre chronologique. Nous :\n",
    "\n",
    "1. Chargons les données et appliquons la fonction `inputTransform` pour générer les features.\n",
    "2. Choisissons une date de coupure (par exemple le 20 février 2024) pour séparer le jeu de données :\n",
    "   - **Train** : Données avant le 20 février 2024.\n",
    "   - **Test** : Données à partir du 20 février 2024.\n",
    "3. Entraînons le modèle uniquement sur l'ensemble d'entraînement.\n",
    "4. Évaluons le modèle sur l'ensemble de test pour obtenir une mesure plus réaliste de ses performances futures.\n",
    "5. Présentons les résultats (métriques, graphiques) pour comparer le train et le test.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45755d",
   "metadata": {},
   "source": [
    "## Chargement des bibliothèques\n",
    "\n",
    "- `pandas` et `numpy` pour la manipulation des données et les calculs.\n",
    "- `matplotlib` pour la visualisation.\n",
    "- `sklearn` pour l'entraînement du modèle et l'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a564d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #type: ignore\n",
    "import numpy as np  #type: ignore\n",
    "import matplotlib.pyplot as plt  #type: ignore\n",
    "from sklearn.ensemble import RandomForestRegressor  #type: ignore\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error  #type: ignore\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score  #type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8abea3",
   "metadata": {},
   "source": [
    "## Paramètres et Chemins d'accès\n",
    "\n",
    "- `input_filename` : Fichier contenant les données complètes, non défectueuses, avec la cible y.\n",
    "- `hold_out_filename` : Fichier contenant les données défectueuses (sans y).\n",
    "- `split_date` : Date de coupure pour séparer entraînement et test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb83f0bd-2a56-4cda-b821-a15ef40a8c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = './projet_2_data.csv'\n",
    "hold_out_filename = './projet_2_hold_out.csv'\n",
    "split_date = pd.Timestamp(\"2024-02-19 12:00:00\")  # Date de coupure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a6430",
   "metadata": {},
   "source": [
    "## Chargement des données initiales\n",
    "\n",
    "Nous chargeons les données brutes (avec y) depuis `projet_2_data.csv`. Nous vérifions l'aperçu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0584e08-d4d7-490b-b0d8-7b1a584bc025",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_filename, parse_dates=['timestamp'])\n",
    "data = data.set_index('timestamp')\n",
    "\n",
    "print(\"Aperçu des données :\")\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f768578c",
   "metadata": {},
   "source": [
    "## Visualisation rapide des données brutes\n",
    "\n",
    "Observons rapidement la série `y` ainsi que `x1` et `x2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641468e7-77f8-401a-ba94-40bff86d9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(12,8), sharex=True)\n",
    "\n",
    "ax[0].plot(data.index, data['y'], label='y', color='blue')\n",
    "ax[0].set_title('y')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(data.index, data['x1'], label='x1', color='orange')\n",
    "ax[1].set_title('x1')\n",
    "ax[1].grid(True)\n",
    "\n",
    "ax[2].plot(data.index, data['x2'], label='x2', color='green')\n",
    "ax[2].set_title('x2')\n",
    "ax[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df3023-8cf8-4cc8-9c96-1f8680866096",
   "metadata": {},
   "source": [
    "Veuillez adapter la fonction ci-dessous pour qu'elle génère une _DataFrame_ pandas utilisable pour l'entraînement ou l'évaluation de votre modèle prédictif à partir d'un fichier CSV de données brutes.\n",
    "\n",
    "Cette fonction doit prendre en paramètre le fichier CSV contenant les données historiques, avec ou sans la variable cible *y*, par example _projet_2_data.csv_ ou _projet_2_hold_out.csv_.\n",
    "\n",
    "Elle doit retourner un tuple Python contenant les éléments suivants, dans cet ordre :\n",
    "\n",
    "1. Une _pandas.DataFrame_ des caractéristiques (_X_) utilisées comme entrées pour le modèle de prédiction.\n",
    "2. Une _pandas.Series_ contenant les valeurs connues de la variable cible (_y_), si celle-ci est présente dans les données. Sinon, la fonction doit retourner _None_ à la place.\n",
    "3. Une _pandas.Series_ des timestamps correspondant aux instants de prédiction de _y_.\n",
    "\n",
    "Assurez-vous que _X_, _y_ (si présent), et les timestamps ont **la même taille** afin de garantir la cohérence des données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716fffbb",
   "metadata": {},
   "source": [
    "## Fonction de transformation des données (inputTransform)\n",
    "\n",
    "Cette fonction prend un fichier CSV et :\n",
    "- Extrait des features temporelles (heure, jour de la semaine).\n",
    "- Crée des transformations cycliques (sin_hour, cos_hour).\n",
    "- Ajoute des lags sur x1 et x2 (15 et 30 minutes).\n",
    "- Retourne X, y, timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd38820d-c861-43ed-9977-2469057ad5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputTransform(file_path: str =hold_out_filename):\n",
    "    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
    "    df = df.set_index('timestamp')\n",
    "    \n",
    "    # Caractéristiques temporelles\n",
    "    df['hour'] = df.index.hour\n",
    "    df['weekday'] = df.index.weekday\n",
    "    df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    \n",
    "    # Lags sur x1 et x2 (1 pas = 15 min, 2 pas = 30 min)\n",
    "    df['x1_lag15'] = df['x1'].shift(1)\n",
    "    df['x1_lag30'] = df['x1'].shift(2)\n",
    "    df['x2_lag15'] = df['x2'].shift(1)\n",
    "    df['x2_lag30'] = df['x2'].shift(2)\n",
    "    \n",
    "    # Supprimer les lignes avec NaN\n",
    "    df = df.dropna()\n",
    "    \n",
    "    features = ['x1', 'x2', 'x1_lag15', 'x1_lag30', 'x2_lag15', 'x2_lag30', 'sin_hour', 'cos_hour', 'weekday']\n",
    "    X = df[features]\n",
    "    y = df['y'] if 'y' in df.columns else None\n",
    "    timestamps = df.index\n",
    "    \n",
    "    return X, y, timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019a02d",
   "metadata": {},
   "source": [
    "## Transformation des données\n",
    "\n",
    "On transforme les données complètes. Ensuite, on fera la séparation temporelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43dc441",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full, y_full, ts_full = inputTransform(input_filename)\n",
    "print(\"Dimensions de X_full :\", X_full.shape)\n",
    "print(\"Dimensions de y_full :\", y_full.shape)\n",
    "print(\"Aperçu de X_full :\")\n",
    "display(X_full.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68807aa0",
   "metadata": {},
   "source": [
    "## Séparation Entraînement/Test\n",
    "\n",
    "Nous utilisons la date de coupure `split_date` (20 février 2024).  \n",
    "- Entraînement : jusqu'au 19 février 2024 inclus.\n",
    "- Test : à partir du 20 février 2024.\n",
    "\n",
    "Cette séparation respecte la chronologie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb81a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = ts_full < split_date\n",
    "test_mask = ts_full >= split_date\n",
    "\n",
    "X_train, y_train = X_full[train_mask], y_full[train_mask]\n",
    "X_test, y_test = X_full[test_mask], y_full[test_mask]\n",
    "\n",
    "print(\"Taille Entraînement :\", X_train.shape, y_train.shape)\n",
    "print(\"Taille Test :\", X_test.shape, y_test.shape)\n",
    "print(\"Min date:\", ts_full.min())\n",
    "print(\"Max date:\", ts_full.max())\n",
    "print(\"Train rows:\", train_mask.sum())\n",
    "print(\"Test rows:\", test_mask.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f8974",
   "metadata": {},
   "source": [
    "## Entraînement du Modèle\n",
    "\n",
    "Nous entraînons le modèle (ici un `RandomForestRegressor`) uniquement sur l'ensemble d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf1a8f",
   "metadata": {},
   "source": [
    "## Évaluation sur l'ensemble d'entraînement\n",
    "\n",
    "Calcul des prédictions et des métriques sur l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eda657",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "mape_train = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100\n",
    "\n",
    "print(\"Entraînement :\")\n",
    "print(\"R²      :\", r2_train)\n",
    "print(\"MSE     :\", mse_train)\n",
    "print(\"RMSE    :\", np.sqrt(mse_train))\n",
    "print(\"MAE     :\", mae_train)\n",
    "print(\"MAPE(%) :\", mape_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed65d0e",
   "metadata": {},
   "source": [
    "## Évaluation sur l'ensemble de test\n",
    "\n",
    "On prédit les valeurs de y pour la période postérieure au 20 février."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "mape_test = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
    "\n",
    "print(\"Test :\")\n",
    "print(\"R²      :\", r2_test)\n",
    "print(\"MSE     :\", mse_test)\n",
    "print(\"RMSE    :\", np.sqrt(mse_test))\n",
    "print(\"MAE     :\", mae_test)\n",
    "print(\"MAPE(%) :\", mape_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812fa59f",
   "metadata": {},
   "source": [
    "## Visualisation des prédictions vs observations réelles sur l'ensemble de test\n",
    "\n",
    "Comparons les valeurs réelles (y_test) et prédites (y_test_pred) sur la période de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(X_test.index, y_test, label='y réel (test)', alpha=0.7)\n",
    "plt.plot(X_test.index, y_test_pred, label='y prédit (test)', alpha=0.7)\n",
    "plt.title(\"Comparaison des valeurs réelles et prédites (Test)\")\n",
    "plt.xlabel(\"Temps\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def5fa8",
   "metadata": {},
   "source": [
    "## Nuage de points des prédictions vs réelles sur le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"y réel (test)\")\n",
    "plt.ylabel(\"y prédit (test)\")\n",
    "plt.title(\"Valeurs prédites vs réelles (Test)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2de8fa",
   "metadata": {},
   "source": [
    "## Analyse des Résidus sur le Test\n",
    "\n",
    "Distribution des résidus (test) et résidus en fonction du temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_test = y_test - y_test_pred\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(residuals_test, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.title(\"Distribution des résidus (Test)\")\n",
    "plt.xlabel(\"Résidu (y - y_prédit)\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(X_test.index, residuals_test, alpha=0.7)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title(\"Résidus en fonction du temps (Test)\")\n",
    "plt.xlabel(\"Temps\")\n",
    "plt.ylabel(\"Résidu\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f54682-de7d-44d1-8d4b-fb9023d6f45c",
   "metadata": {},
   "source": [
    "---\n",
    "#### Verification\n",
    "\n",
    "Veuillez valider votre modèles à l'aide de la fonction ci-dessous, vous devez entrer votre modèle de prédiction, ainsi que la fonction de transformation de la donnée de test (inputGenerator=...).\n",
    "\n",
    "⚠️ - Cette fonction vérifie uniquement que votre soumission est vérifiable. Elle ne donne aucune indication sur la validité de la soumission (e.g. type de ML) ou sa qualité.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd91914-af6f-4dde-ba41-68e8334ee53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executer la commande ci-dessous si nécessaire (enlever le #).\n",
    "# !pip install -e ./eng209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf05c1cd-ccac-4ef8-9080-ce1be8e7fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import eng209.verify\n",
    "reload(eng209.verify)\n",
    "from eng209.verify import verify_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef086c-09f2-4475-acbc-c7187f720aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacez model par votre modèle\n",
    "model = model\n",
    "verify_q2(model, inputGenerator=inputTransform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
